# Math Foundations for Machine Learning

This folder contains **core mathematical concepts** required to understand
machine learning algorithms implemented in this repository.

The goal is **not deep mathematical proofs**, but to build:
- intuition
- ML-oriented understanding
- clear connection between math and code

---

## Why Math Foundations?

Most machine learning algorithms are based on:
- linear algebra
- calculus
- probability & statistics

Instead of treating these as separate subjects, this folder explains
**only the math that is directly used in ML models**.

---

## Contents

### 1. Linear Algebra (`linear_algebra.md`)
Covers:
- scalars, vectors, matrices
- dot product and matrix multiplication
- how data and weights are represented
- why linear algebra is the backbone of ML and neural networks

Used in:
- Linear Regression
- Logistic Regression
- Neural Networks
- PCA

---

### 2. Calculus (`calculus.md`)
Covers:
- derivatives (intuition-based)
- gradients
- chain rule
- gradient descent

Used in:
- model training
- loss minimization
- backpropagation

---

### 3. Probability & Statistics (`probability_statistics.md`)
Covers:
- mean and variance
- probability concepts
- loss functions
- basic statistical intuition for ML

Used in:
- regression and classification
- evaluation metrics
- probabilistic models

---

## How to Use This Folder

- Read these files **before** jumping into algorithms
- Refer back when something feels unclear in model code
- Think in terms of:  
  **math → algorithm → implementation**

---

## Learning Philosophy

> “You don’t need to know all math.  
> You need to know the right math, applied correctly.”

This folder follows that principle.

